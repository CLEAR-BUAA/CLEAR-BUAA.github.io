<!DOCTYPE html>
<html>
<head>
    <title>CLEAR-BUAA's homepage</title>
    <!-- Custom Theme files -->
    <link rel="icon" href="./images/label_logo_only.jpg">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
    <meta name="keywords" content=""/>
    <script type="application/x-javascript"> addEventListener("load", function () {
        setTimeout(hideURLbar, 0);
    }, false);

    function hideURLbar() {
        window.scrollTo(0, 1);
    } </script>
    <!-- //Custom Theme files -->
    <link href="css/bootstrap.css" type="text/css" rel="stylesheet" media="all">
    <link href="css/style.css" type="text/css" rel="stylesheet" media="all">
    <link rel="stylesheet" href="css/lightbox.css">
    <!-- js -->
    <script src="js/jquery-1.11.1.min.js"></script>
    <!-- //js -->
    <!--web-fonts-->
    <link href='https://fonts.googleapis.com/css?family=Roboto+Condensed:400,300,300italic,400italic,700,700italic'
          rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Dosis:400,200,300,500,600,700,800' rel='stylesheet'
          type='text/css'>
    <!--//web-fonts-->
    <!--circle-chart-->
    <script src="js/jquery.circlechart.js"></script>
    <!--circle-chart-->
</head>
<body>
<!--header-->
<div class="header">
    <nav class="navbar navbar-default">
        <div class="container">
            <div class="navbar-header navbar-left">
                <h1><a href="index.html"><img style="width: 30rem" src="images/lab_logo.png"/></a></h1>
            </div>
            <!--navigation-->
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
                    data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <div class="header-right">
                <div class="top-nav-text">
                </div>
                <!-- Collect the nav links, forms, and other content for toggling -->
                <div class="collapse navbar-collapse navbar-right" id="bs-example-navbar-collapse-1">
                    <ul class="nav navbar-nav navbar-left">
                        <li><a href="index.html" class="scroll">Home</a></li>
                        <li><a href="publication.html" class="active">Publications</a></li>
                        <li><a href="people.html" class="scroll">Members</a></li>
                        <li><a href="seminar.html" class="scroll">Seminar</a></li>
                        <li><a href="opening.html" class="scroll">Join Us</a></li>
                    </ul>
                    <div class="clearfix"></div>
                </div><!--//navigation-->
            </div>
            <div class="clearfix"></div>
        </div>
    </nav>
</div>
<!--//header-->

<div id="publication" class="publication">
    <div class="container">


        <h4 class="title"> Selected Journal Articles </h4>
        <ol>
            <li>
                <strong>ReCLIP++: Learn to Rectify the Bias of CLIP for Unsupervised Semantic Segmentation</strong> <br>
                J. Wang, <strong>G. Kang</strong><br>
                International Journal of Computer Vision (<strong>IJCV</strong>)
                <a href="https://arxiv.org/abs/2408.06747">[PDF]</a>
                <a href="https://github.com/dogehhh/ReCLIP">[Code]</a>
            </li>
            <li>
                <strong>PLGS: Robust Panoptic Lifting with 3D Gaussian Splatting</strong> <br>
                Y. Wang, X. Wei, M. Lu, <strong>G. Kang</strong><br>
                IEEE Transactions on Image Processing (<strong>TIP</strong>)
                <a href="https://arxiv.org/pdf/2410.17505">[PDF]</a>
        
            </li>
            <li>
                <strong>Normalizing Batch Normalization for Long-Tailed Recognition</strong> <br>
                Y. Bao, <strong>G. Kang</strong>, L. Yang, X. Duan, B. Zhao, B. Zhang<br>
                IEEE Transactions on Image Processing (<strong>TIP</strong>)
                <a href="https://arxiv.org/abs/2501.03122">[PDF]</a>
                <a href="https://github.com/yuxiangbao/NBN">[Code]</a>
                
                
            </li>
            <li>
                <strong>Ov-vis: Open-vocabulary video instance segmentation</strong> <br>
                H. Wang, C. Yan, K. Chen, X. Jiang, X. Tang, Y. Hu, <strong>G. Kang</strong>, W. Xie, E. Gavves<br>
                International Journal of Computer Vision(<strong>IJCV</strong>)
                <a href="https://arxiv.org/abs/2305.16835">[PDF]</a>
<!--                 <a href="">[Code]</a> -->
            </li>
            <li>
                <strong>Taking a closer look at factor disentanglement: Dual-path variational autoencoder learning for domain generalization</strong> <br>
                Y. Luo, <strong>G. Kang</strong>, K. Liu, F. Zhuang, J. Li<br>
                IEEE Transactions on Multimedia (<strong>TMM</strong>)
                <a href="https://dl.acm.org/doi/abs/10.1109/TMM.2023.3340552">[PDF]</a>
<!--                 <a href="">[Code]</a> -->
            </li>
            <li>
                <strong>DropQueries: A Simple Way to Discover Comprehensive Segment Representations</strong> <br>
                H. Ding, B. Wang, <strong>G. Kang</strong>, W. Li, C. He, Y. Zhao, Y. Wei<br>
                IEEE Transactions on Multimedia (<strong>TMM</strong>)
                <a href="https://ieeexplore.ieee.org/document/10239324">[PDF]</a>
<!--                 <a href="">[Code]</a> -->
            </li>
            <li>
                <strong>Contrastive adaptation network for single-and multi-source domain adaptation</strong> <br>
                <strong>G. Kang</strong>, L. Jiang, Y. Wei, Y. Yang, A. Hauptmann<br>
                IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>)
                <a href="https://ieeexplore.ieee.org/document/9219132">[PDF]</a>
<!--                 <a href="">[Code]</a> -->
            </li>
            <li>
                <strong>Shakeout: A new approach to regularized deep neural network training</strong> <br>
                <strong>G. Kang</strong>, J. Li, D. Tao<br>
                IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>)
                <a href="https://arxiv.org/abs/1904.06593">[PDF]</a>
                <a href="https://github.com/kgl-prml/shakeout-for-caffe">[Code]</a>
            </li>
        </ol>


        
        <h4 class="title"> Selected Conference Proceedings </h4>

        <h3 class="title subtitle">2025</h3>
        <ol>
            <li>
                <strong>FreeInv: Free Lunch for Improving DDIM Inversion</strong> <br>
                Y Bao, H Liu, X Gao, H Fu, <strong>G. Kang</strong><br>
                 Neural Information Processing Systems (<strong>NeurIPS</strong>), 2025
                <a href="https://arxiv.org/pdf/2503.23035">[PDF]</a>
<!--                 <a href="">[Code]</a> -->
            </li>
            <li>
                <strong>Enhancing Visual Reliance in Text Generation: A Bayesian Perspective on Mitigating Hallucination in Large Vision-Language Models</strong> <br>
                N. Hu, X. Duan, J. Zhang, <strong>G. Kang</strong><br>
                ACM International Conference on Multimedia (<strong>ACMMM</strong>), 2025
                <a href="https://arxiv.org/abs/2505.19498">[PDF]</a>
                <a href="https://github.com/NeilHnxTcc/EVRB/tree/main">[Code]</a>
            </li>
            <li>
                <strong>Separate Motion from Appearance: Customizing Motion via Customizing Text-to-Video Diffusion Models</strong> <br>
                H. Liu, J. Wang, S. Ma, J. Hu, X. Wei, <strong>G. Kang</strong><br>
                ACM International Conference on Multimedia (<strong>ACMMM</strong>), 2025
                <a href="https://arxiv.org/abs/2501.16714">[PDF]</a>
                <a href="https://github.com/LiuHuijie6410/SeperateMotionFromAppearance">[Code]</a>
            </li>
            
             <li>
                <strong>Cross-Domain Attribute Alignment with CLIP: A Rehearsal-Free Approach for Class-Incremental Unsupervised Domain Adaptation</strong> <br>
                K. Mi, <strong>G. Kang</strong>, G. Li, L. Zhao, T. Zhou, C. Gong
                ACM International Conference on Multimedia (<strong>ACMMM</strong>), 2025
<!--                 <a href="">[PDF]</a>
                <a href="">[Code]</a> -->
            </li>
            
            <li>
                <strong>Efficient and Accurate Prompt Optimization: the Benefit of Memory in Exemplar-Guided Reflection</strong> <br>
                C. Yan, J. Wang, L. Zhang, R. Zhao, X. Wu, K. Xiong, Q. Liu, <strong>G. Kang</strong>, Y. Kang<br>
                Annual Meeting of the Association for Computational Linguistics (<strong>ACL main</strong>),2025
                <a href="https://arxiv.org/abs/2411.07446">[PDF]</a>
                <a href="https://github.com/fak111/autoprompt">[Code]</a>
            </li>
        </ol>
        <h3 class="title subtitle">2024</h3>
        <ol>
            <li>
                <strong>Visa: Reasoning video object segmentation via large language models</strong> <br>
                C. Yan, H. Wang, S. Yan, X. Jiang, Y. Hu, <strong>G. Kang</strong>, W. Xie, E. Gavves<br>
                European Conference on Computer Vision (<strong>ECCV</strong>), 2024
                <a href="https://arxiv.org/abs/2407.11325">[PDF]</a>
                <a href="https://github.com/cilinyan/VISA">[Code]</a>
            </li>
            <li>
                <strong>Tuning-free inversion-enhanced control for consistent image editing</strong> <br>
                X. Duan, S. Cui, <strong>G. Kang</strong>, B. Zhang, Z. Fei, M. Fan, J. Huang<br>
                Proceedings of the AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 2024
                <a href="https://arxiv.org/abs/2312.14611">[PDF]</a>
<!--                 <a href="">[Code]</a> -->
            </li>
            <li>
                <strong>Learn to rectify the bias of CLIP for unsupervised semantic segmentation</strong> <br>
                J. Wang, <strong>G. Kang</strong><br>
                Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2024
                <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_Learn_to_Rectify_the_Bias_of_CLIP_for_Unsupervised_Semantic_CVPR_2024_paper.pdf">[PDF]</a>
                <a href="https://github.com/dogehhh/ReCLIP">[Code]</a>
            </li>
        </ol>
        <h3 class="title subtitle">2023</h3>
        <ol>
            <li>
                <strong>SLCA: Slow Learner with Classifier Alignment for Continual Learning on a Pre-trained Model</strong> <br>
                G. Zhang, L. Wang, <strong>G. Kang</strong>, L. Chen, Y. Wei<br>
                International Conference on Computer Vision (<strong>ICCV</strong>) 2023
                <a href="https://arxiv.org/abs/2303.05118">[PDF]</a>
                <a href="https://github.com/GengDavid/SLCA">[Code]</a>
            </li>
            <li>
                <strong>Attriclip: A non-incremental learner for incremental knowledge learning</strong> <br>
                R. Wang, X. Duan, <strong>G. Kang</strong>, J. Liu, S. Lin, S. Xu, J. Li, B. Zhang<br>
                Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2023
                <a href="http://arxiv.org/abs/2305.11488">[PDF]</a>
                <a href="https://github.com/vanity1129/AttriCLIP">[Code]</a>
            </li>
            <li>
                <strong>Adversarially masking synthetic to mimic real: Adaptive noise injection for point cloud segmentation adaptation</strong> <br>
                G. Li, <strong>G. Kang</strong>, X. Wang, Y. Wei, Y. Yang<br>
                Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2023
                <a href="https://ieeexplore.ieee.org/document/10204049">[PDF]</a>
<!--                 <a href="">[Code]</a> -->
            </li>
        </ol>
        
        <h3 class="title subtitle">2022 and Before </h3>
        <ol>
            <li>
                <strong>Few-shot segmentation via cycle-consistent transformer</strong> <br>
                G. Zhang, <strong>G. Kang</strong>, Y. Yang, Y. Wei<br>
                Neural Information Processing Systems (<strong>NeurIPS</strong>), 2021
                <a href="https://arxiv.org/abs/2106.02320">[PDF]</a>
                <a href="https://github.com/GengDavid/CyCTR">[Code]</a>
            </li>
            <li>
                <strong>Domain consensus clustering for universal domain adaptation</strong> <br>
                G. Li, <strong>G. Kang</strong>, Y. Zhu, Y. Wei, Y. Yang<br>
                Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2021
                <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Domain_Consensus_Clustering_for_Universal_Domain_Adaptation_CVPR_2021_paper.pdf">[PDF]</a>
                <a href="https://github.com/Solacex/Domain-Consensus-Clustering">[Code]</a>
            </li>
            <li>
                <strong>Content-consistent matching for domain adaptive semantic segmentation</strong> <br>
                G. Li*, <strong>G. Kang*</strong>, W. Liu, Y. Wei, Y. Yang<br>
                European Conference on Computer Vision (<strong>ECCV</strong>), 2020
                <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123590426.pdf">[PDF]</a>
                <a href="https://github.com/Solacex/CCM">[Code]</a>
            </li>
            <li>
                <strong>Random erasing data augmentation</strong> <br>
                Z. Zhong, L. Zheng, <strong>G. Kang</strong>, S. Li, Y. Yang<br>
                Proceedings of the AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 2020
                <a href="https://arxiv.org/abs/1708.04896">[PDF]</a>
                <a href="https://github.com/zhunzhong07/Random-Erasing">[Code]</a>
            </li>
            <li>
                <strong>Pixel-Level Cycle Association: A New Perspective for Domain Adaptive Semantic Segmentation</strong> <br>
                <strong>G. Kang</strong>, Y. Wei, Y. Yang, Y. Zhuang, A. Hauptmann<br>
                Neural Information Processing Systems (<strong>NeurIPS Oral</strong>), 2020
                <a href="https://arxiv.org/abs/2011.00147">[PDF]</a>
                <a href="https://github.com/kgl-prml/Pixel-Level-Cycle-Association">[Code]</a>
            </li>
            <li>
                <strong>Contrastive adaptation network for unsupervised domain adaptation</strong> <br>
                <strong>G. Kang</strong>, L. Jiang, Y. Yang, A. Hauptmann<br>
                Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2019
                <a href="https://arxiv.org/abs/1901.00976">[PDF]</a>
                <a href="https://github.com/kgl-prml/Contrastive-Adaptation-Network-for-Unsupervised-Domain-Adaptation">[Code]</a>
            </li>
            <li>
                <strong>Annotation efficient cross-modal retrieval with adversarial attentive alignment</strong> <br>
                P.-Y. Huang, <strong>G. Kang</strong>, W. Liu, X. Chang, A. Hauptmann<br>
                ACM International Conference on Multimedia (<strong>ACMMM</strong>), 2019
                <a href="https://dl.acm.org/doi/10.1145/3343031.3350894">[PDF]</a>
<!--                 <a href="">[Code]</a> -->

            </li>
            <li>
                <strong>Attract or distract: Exploit the margin of open set</strong> <br>
                Q. Feng, <strong>G. Kang</strong>, H. Fan, Y. Yang<br>
                International Conference on Computer Vision (<strong>ICCV</strong>), 2019
                <a href="https://arxiv.org/abs/1908.01925">[PDF]</a>
                <a href="https://github.com/qy-feng/Margin-Openset">[Code]</a>
            </li>
            <li>
                <strong>Soft filter pruning for accelerating deep convolutional neural networks</strong> <br>
                Y. He, <strong>G. Kang</strong>, X. Dong, Y. Fu, Y. Yang<br>
                International Joint Conferences on Artificial Intelligence (<strong>IJCAI</strong>) 2018
                <a href="https://arxiv.org/abs/1808.06866">[PDF]</a>
                <a href="https://github.com/he-y/soft-filter-pruning">[Code]</a>
            </li>
            <li>
                <strong>Deep adversarial attention alignment for unsupervised domain adaptation: the benefit of target expectation maximization</strong> <br>
                <strong>G. Kang</strong>, L. Zheng, Y. Yan, Y. Yang<br>
                European Conference on Computer Vision (<strong>ECCV</strong>),2018
                <a href="https://arxiv.org/abs/1801.10068">[PDF]</a>
<!--                 <a href="">[Code]</a> -->
            </li>
            <li>
                <strong>Shakeout: A New Regularized Deep Neural Network Training Scheme</strong> <br>
                <strong>G. Kang</strong>, J. Li, D. Tao<br>
                Proceedings of the AAAI Conference on Artificial Intelligence (<strong>AAAI Oral</strong>), 2016
                <a href="https://arxiv.org/abs/1904.06593">[PDF]</a>
<!--                 <a href="">[Code]</a> -->
            </li>
        </ol>
        
    </div>
</div>

<!--//services-->

<!--footer-->
<div class="footer">
    <div class="container">
        <div class="col-md-5 col-md-offset-2">
            <p>Copyright &copy; 2021.Company name All rights reserved. </p>
        </div>
        <div class="col-md-3">
            <script type="text/javascript"
                    src="//rf.revolvermaps.com/0/0/4.js?i=2hlmeh3dic1&amp;m=0&amp;h=64&amp;c=ff0000&amp;r=0"
                    async="async"></script>
        </div>
    </div>
        <!--banner Slider starts Here-->
    <script src="js/responsiveslides.min.js"></script>
    <script>
        // You can also use "$(window).load(function() {"
        $(function () {
            // Slideshow 3
            $("#slider3").responsiveSlides({
                auto: true,
                pager: true,
                nav: false,
                speed: 500,
                namespace: "callbacks",
                before: function () {
                    $('.events').append("<li>before event fired.</li>");
                },
                after: function () {
                    $('.events').append("<li>after event fired.</li>");
                }
            });

        });
    </script>
    <!--//End-slider-script-->
    <!-- start-smooth-scrolling-->
    <script type="text/javascript" src="js/move-top.js"></script>
    <script type="text/javascript" src="js/easing.js"></script>

    <!--//end-smooth-scrolling-->
    <!--smooth-scrolling-of-move-up-->

    <!--//smooth-scrolling-of-move-up-->
    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="js/bootstrap.js"></script>
</body>
</html>













